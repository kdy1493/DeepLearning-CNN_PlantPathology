# PlantPathology(DeepLearning & CNN í™œìš©)
> Kaggle ê²½ì§„ëŒ€íšŒ Plant Pathology 2020 - FGVC7
<img width="80%" src="https://user-images.githubusercontent.com/116260619/211987672-fa454b9a-14b4-40a1-8818-d1058959bae0.png"/>

#### ì£¼ì œ : KaggleCompetition_Plantpathology(ì‹ë¬¼ ë³‘ë¦¬í•™)

> ë¬¸ì œ ì„¤ëª…
ë†ì‘ë¬¼ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë§ì€ ì§ˆë³‘ì˜ ì˜¤ì§„ì€ í™”í•™ ë¬¼ì§ˆì˜ ì˜¤ìš©ìœ¼ë¡œ ì´ì–´ì ¸ ë‚´ì„± ë³‘ì›ê·  ê· ì£¼ì˜ ì¶œí˜„, íˆ¬ì… ë¹„ìš© ì¦ê°€, ìƒë‹¹í•œ ê²½ì œì  ì†ì‹¤ ë° í™˜ê²½ ì˜í–¥ìœ¼ë¡œ ë” ë§ì€ ë°œë³‘ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ê°„ ì •ì°°ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” í˜„ì¬ ì§ˆë³‘ ì§„ë‹¨ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ì»´í“¨í„° ë¹„ì „ ê¸°ë°˜ ëª¨ë¸ì´ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆì§€ë§Œ ê°ì—¼ëœ ì¡°ì§ì˜ ë‚˜ì´, ìœ ì „ì  ë³€ì´, ë‚˜ë¬´ ë‚´ ì¡°ëª… ì¡°ê±´ìœ¼ë¡œ ì¸í•´ ì§„ë‹¨ì„ ê°ì†Œì‹œí‚µë‹ˆë‹¤.

> íŠ¹ì • ëª©í‘œ

  ì‹ë¬¼ ë³‘ë¦¬í•™ ì±Œë¦°ì§€'ì˜ ëª©í‘œëŠ” í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
- í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ ë‹¤ë¥¸ ì§ˆë³‘ ë²”ì£¼ ë˜ëŠ” ê±´ê°•í•œ ììœ¼ë¡œ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
- ë§ì€ ì§ˆë³‘, ë•Œë¡œëŠ” í•œ ìì— í•˜ë‚˜ ì´ìƒì˜ ì§ˆë³‘ì„ ì •í™•í•˜ê²Œ êµ¬ë³„í•©ë‹ˆë‹¤. 
- í¬ê·€ í´ë˜ìŠ¤ ë° ìƒˆë¡œìš´ ì¦ìƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. 
- ì£¼ì†Œ ê¹Šì´ ì¸ì‹ - ê°ë„, ë¹›, ê·¸ëŠ˜, ìì˜ ìƒë¦¬í•™ì  ë‚˜ì´; 
- ì‹ë³„, ì£¼ì„, ì •ëŸ‰í™” ë° ì»´í“¨í„° ë¹„ì „ ì•ˆë‚´ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ í†µí•©í•˜ì—¬ í•™ìŠµ ì¤‘ì— ê´€ë ¨ ê¸°ëŠ¥ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

# ì œì¶œê²°ê³¼
<img width="80%" src="https://user-images.githubusercontent.com/116260619/211987468-971f6824-1916-43fd-a1f1-db747f375fd0.png"/>

# íŒ€ì›
- ê³ ì„ì£¼
- ë‚¨ì •ìš°
- ê°•ë™ì—½

# ëª©ì°¨
- [DataSet](#DataSet)
  - ë°ì´í„° ë‹¤ìš´ë¡œë“œ
  - ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  - ë°ì´í„° ì ì¬



- [EDA](#EDA)
  - ë°ì´í„° í›‘ì–´ë³´ê¸°
  - ì‹œê°í™”

- [DataSet](#DataSet)


- [DataProcessing](#DataProcessing)


- [CreateModel](#CreateModel)


- [CompileModel](#CompileModel)


- [TrainingModel](#TrainingModel)

 
- [SaveModel](#SaveModel)

- [TestSubmission](#TestSubmission)
```python
import torch 
import random
import numpy as np
import os
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.gridspec as gridspec
import cv2

```


```python
seed = 42
os.environ['PYTHONHASHSEED'] = str(seed)
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.enabled = False
```


```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

device
```




    device(type='cuda')



# DataSet

## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°


```python
import pandas as pd

# ë°ì´í„° ê²½ë¡œ
data_path = '/kaggle/input/plant-pathology-2020-fgvc7/'

train = pd.read_csv(data_path + 'train.csv')
test = pd.read_csv(data_path + 'test.csv')
submission = pd.read_csv(data_path + 'sample_submission.csv')
from sklearn.model_selection import train_test_split

# train : valid =  0.9 : 0.1
train, valid = train_test_split(train, 
                                test_size=0.1,
                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],
                                random_state=42)
```

# EDA

## ë°ì´í„° í›‘ì–´ë³´ê¸°


```python
train.shape, test.shape
```




    ((1638, 5), (1821, 1))




```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image_id</th>
      <th>healthy</th>
      <th>multiple_diseases</th>
      <th>rust</th>
      <th>scab</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>379</th>
      <td>Train_379</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1556</th>
      <td>Train_1556</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>448</th>
      <td>Train_448</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1202</th>
      <td>Train_1202</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1541</th>
      <td>Train_1541</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
test.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Test_0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Test_1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Test_2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Test_3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Test_4</td>
    </tr>
  </tbody>
</table>
</div>




```python
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image_id</th>
      <th>healthy</th>
      <th>multiple_diseases</th>
      <th>rust</th>
      <th>scab</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Test_0</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Test_1</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Test_2</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Test_3</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Test_4</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
  </tbody>
</table>
</div>



- healthy : ê±´ê°•í•¨
- multiple_diseases : ì—¬ëŸ¬ ì§ˆë³‘
- rust : ë…¹ë³‘ê· 
- scab : ë¶‰ì€ ê³°íŒ¡ì´ë³‘


```python
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 1638 entries, 379 to 1746
    Data columns (total 5 columns):
     #   Column             Non-Null Count  Dtype 
    ---  ------             --------------  ----- 
     0   image_id           1638 non-null   object
     1   healthy            1638 non-null   int64 
     2   multiple_diseases  1638 non-null   int64 
     3   rust               1638 non-null   int64 
     4   scab               1638 non-null   int64 
    dtypes: int64(4), object(1)
    memory usage: 76.8+ KB
    

## ë°ì´í„° ì‹œê°í™”


```python
# Extract data for each target value
healthy = train.loc[train['healthy']==1]
multiple_diseases = train.loc[train['multiple_diseases']==1]
rust = train.loc[train['rust']==1]
scab = train.loc[train['scab']==1]
```


```python
healthy.shape, multiple_diseases.shape, rust.shape, scab.shape
```




    ((464, 5), (82, 5), (559, 5), (533, 5))




```python
diseases = dict()

for column in ["healthy","multiple_diseases","rust","scab"]:
    counts = pd.DataFrame(train[column].value_counts())
    diseases[column] = counts.iloc[1,0]
    
#bar chart to show different diseases    
fig, (ax1, ax2) = plt.subplots(2, 1,figsize=(15,25))
ax1.bar(diseases.keys(),diseases.values(), color=["#6666ff"])
ax1.set_title('Bar Chart', fontsize=18)

ax2.pie(diseases.values(),labels = diseases.keys(), colors=["#6666ff","#4da6ff","#1ac6ff","#c44dff"], autopct='%1.1f%%')
ax2.set_title('Pie Chart', fontsize=18)
ax2.axis('equal') 

plt.show()
```
<img  src="https://user-images.githubusercontent.com/116260619/212005231-13f51be8-b2f1-49d9-9abf-fbff66606f86.png"/>

 
    



```python

def show_image(img_ids, rows=2, cols=3):
    assert len(img_ids) <= rows * cols # ì´ë¯¸ì§€ê°€ í–‰/ì—´ ê°œìˆ˜ë³´ë‹¤ ë§ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
    
    plt.figure(figsize=(15,8))
    grid = gridspec.GridSpec(rows, cols)
    
    for idx, img_id in enumerate(img_ids):
        img_path = f'{data_path}/images/{img_id}.jpg'
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        ax = plt.subplot(grid[idx])
        ax.imshow(image)
```


```python
num_of_imgs=6
last_healthy_img_ids = healthy['image_id'][-num_of_imgs:]
last_multiple_diseases_img_ids = multiple_diseases['image_id'][-num_of_imgs:]
last_rust_img_ids = rust['image_id'][-num_of_imgs:]
last_scab_img_ids = scab['image_id'][-num_of_imgs:]
show_image(last_healthy_img_ids)
```
<img  src="https://user-images.githubusercontent.com/116260619/212005243-8ee72989-b7d5-4a6e-9089-a12a295078b1.png"/>




```python
im_healthy = plt.imread(data_path+'/images/Train_2.jpg', format = 'jpg')
im_multi = plt.imread(data_path+'/images/Train_1.jpg', format = 'jpg')
im_rust = plt.imread(data_path+'/images/Train_3.jpg', format = 'jpg')
im_scab = plt.imread(data_path+'/images/Train_0.jpg', format = 'jpg')

fig = plt.figure(figsize=(16,10))
ax = fig.add_subplot(2, 2, 1)
ax.imshow(im_healthy)
ax.set_title(0, fontsize = 20)

ax = fig.add_subplot(2, 2, 2)
ax.imshow(im_multi)
ax.set_title(1, fontsize = 20)

ax = fig.add_subplot(2, 2, 3)
ax.imshow(im_rust)
ax.set_title(2, fontsize = 20)

ax = fig.add_subplot(2, 2, 4)
ax.imshow(im_scab)
ax.set_title(3, fontsize = 20)
```
<img  src="https://user-images.githubusercontent.com/116260619/212005250-fd307deb-bc73-47cf-a48f-8c73371e8a18.png"/>



    Text(0.5, 1.0, '3')






# DataPreprocessing


```python
import cv2
from torch.utils.data import Dataset 
import numpy as np

class ImageDataset(Dataset):
    # ìƒì„±ì
    def __init__(self, df, img_dir='./', transform=None, is_test=False):
        super().__init__() # ìƒì†ë°›ì€ Datasetì˜ __init__() ë©”ì„œë“œ í˜¸ì¶œ
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test

    # ë°ì´í„°ì…‹ ë°˜í™˜
    def __len__(self):
        return len(self.df)

    # indexí•´ë‹¹ ë°˜í™˜
    def __getitem__(self, idx):
        img_id = self.df.iloc[idx, 0]             # ID
        img_path = self.img_dir + img_id + '.jpg' # ê²½ë¡œ
        image = cv2.imread(img_path)              # íŒŒì¼ ì½ê¸°
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # ìƒ‰ìƒ ë³´ì •
        # ì´ë¯¸ì§€ ë³€í™˜ 
        if self.transform is not None:
            image = self.transform(image=image)['image']
        if self.is_test:
            return image 
        else:
            # íƒ€ê¹ƒê°’ 4ê°œ ì¤‘ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ 
            label = np.argmax(self.df.iloc[idx, 1:5]) 
            return image, label # í›ˆë ¨/ê²€ì¦ìš©ì¼ ë•Œ
```


```python
# ì´ë¯¸ì§€ ë³€í™˜(albumentations)
import albumentations as A
from albumentations.pytorch import ToTensorV2
```


```python
# í›ˆë ¨ ë°ì´í„°ìš© ë³€í™˜ê¸°
transform_train = A.Compose([
    A.Resize(450, 650),       
    A.RandomBrightnessContrast(brightness_limit=0.2, # ë°ê¸° ëŒ€ë¹„ ì¡°ì ˆ
                               contrast_limit=0.2, p=0.3),
    A.VerticalFlip(p=0.2),    
    A.HorizontalFlip(p=0.5),   
    A.ShiftScaleRotate(       
        shift_limit=0.1,
        scale_limit=0.2,
        rotate_limit=30, p=0.3),
    A.OneOf([A.Emboss(p=1),   
             A.Sharpen(p=1),
             A.Blur(p=1)], p=0.3),
    A.PiecewiseAffine(p=0.3), 
    A.Normalize(),            
    ToTensorV2()             
])
```


```python
transform_test = A.Compose([
    A.Resize(450, 650),
    A.Normalize(),      
    ToTensorV2()       
])
```


```python
img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'

dataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)
dataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)
```


```python
def seed_worker(worker_id):
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

g = torch.Generator()
g.manual_seed(0)
```




    <torch._C.Generator at 0x7f075fbaaed0>



ì‘ì—…ì†ë„ë¥¼ ìœ„í•œ ë©€í‹°í”„ë¡œì„¸ì‹±


```python
from torch.utils.data import DataLoader

batch_size = 4

trainloader = DataLoader(dataset_train, batch_size=batch_size, 
                          shuffle=True, worker_init_fn=seed_worker,
                          generator=g, num_workers=2)
validloader = DataLoader(dataset_valid, batch_size=batch_size, 
                          shuffle=False, worker_init_fn=seed_worker,
                          generator=g, num_workers=2)
testloader = DataLoader(dataset_test, batch_size=batch_size, 
                         shuffle=False, worker_init_fn=seed_worker,
                         generator=g, num_workers=2)
```


```python
testloader = DataLoader(dataset_test, batch_size=batch_size, 
                         shuffle=False, worker_init_fn=seed_worker,
                         generator=g, num_workers=2)
```

# CreateModel

> EfficientNet-B07


```python
!pip install efficientnet-pytorch==0.7.1
from efficientnet_pytorch import EfficientNet # EfficientNet ëª¨ë¸
# ì‚¬ì „ í›ˆë ¨ëœ efficientnet-b7 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) 
model = model.to(device)
```

    Collecting efficientnet-pytorch==0.7.1
      Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)
      Preparing metadata (setup.py) ... [?25ldone
    [?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.7.1) (1.11.0)
    Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.1.1)
    Building wheels for collected packages: efficientnet-pytorch
      Building wheel for efficientnet-pytorch (setup.py) ... [?25ldone
    [?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=4ad2699be0275e07618b737be6d3a17ad967edc977cfc9a76e14bb3843a9ec32
      Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6
    Successfully built efficientnet-pytorch
    Installing collected packages: efficientnet-pytorch
    Successfully installed efficientnet-pytorch-0.7.1
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0m

    Downloading: "https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth
    


      0%|          | 0.00/254M [00:00<?, ?B/s]


    Loaded pretrained weights for efficientnet-b7
    

> ResNet50


```python
# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
# from tensorflow.keras.preprocessing.image import load_img, img_to_array

# from torchvision import models

# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = models.resnet50(pretrained=True).to(device) 
```

    Downloading: "https://download.pytorch.org/models/resnet50-0676ba61.pth" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth
    


      0%|          | 0.00/97.8M [00:00<?, ?B/s]


# ModelCompile


```python
import torch.nn as nn # ì‹ ê²½ë§ ëª¨ë“ˆ
from tqdm import tqdm
# í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ ì†ì‹¤í•¨ìˆ˜ ì„¤ì •(ë‹¤ì¤‘ë¶„ë¥˜)
criterion = nn.CrossEntropyLoss()

# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001) # ëª¨ë¸íŒŒë¼ë¯¸í„°,ëŸ¬ë‹ë ˆì´íŠ¸, ê°€ì¤‘ì¹˜ê°ì‡ 
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=7, factor=0.1, verbose=True)
```

# TrainingModel


```python
def validation(model, validloader, criterion):
  valid_accuracy = 0
  valid_loss = 0

  with torch.no_grad():
    for images, labels in validloader: 
      
      images, labels = images.to(device), labels.to(device)

      # Predict forward
      logits = model.forward(images) 
      _, preds = torch.max(logits, 1)
      # preds= probs.max(dim=1)[1] 
      correct = (preds == labels).sum()

      accuracy = correct / images.shape[0]
      loss = criterion(logits, labels) 
      
      valid_accuracy += accuracy
      valid_loss += loss.item() 
    

  return valid_loss, valid_accuracy

```


```python
from torch.utils.tensorboard import SummaryWriter

writer  = SummaryWriter()
```


```python
def train(model, epochs, criterion, optimizer):
  train_loss = []
  valid_loss = []
  train_acc = []
  val_acc = []
  steps = 0
  min_loss = 10000
  max_accuracy = 0

  trigger = 0
  patience = 5 # for Early stopping

  # 1 ì—í­(epoch)ë‹¹ ë°˜ë³µìˆ˜
  steps_per_epoch = len(trainloader) # 2500 iterations

  for epoch in range(epochs):
    model.train()
    train_loss = 0
    for images, labels in tqdm(trainloader): # ë¯¸ë‹ˆë°°ì¹˜ 16ê°œì”©ì„ ê°€ì ¸ì™€ images, labelsì— ì¤€ë¹„
      steps += 1
      # Dataë¥¼ GPUë¡œ ë³´ë‚´ê¸°
      images, labels = images.to(device), labels.to(device)

      # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
      # not Flatten!!
      # images.resize_(images.size()[0], 784) # 16, 1, 28, 28

      # Forward ì˜ˆì¸¡
      outputs = model.forward(images) 
      loss = criterion(outputs, labels) 

      # Backward Gradient ì „íŒŒ
      optimizer.zero_grad() #  gradientê°€ ëˆ„ì ë˜ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•´
      loss.backward()

      # ê²½ì‚¬í•˜ê°•ë²•
      optimizer.step()

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0:
        model.eval() 
        valid_loss, valid_accuracy = validation(model, validloader, criterion)

        # tensorboad ì‹œê°í™”
        writer.add_scalar("Loss/train", train_loss/len(trainloader), epoch)
        writer.add_scalar("Loss/valid", valid_loss/len(validloader), epoch)
        writer.add_scalars("Loss/train and valid",
                          {'train' : train_loss/len(trainloader),
                          'valid' : valid_loss/len(validloader)}, epoch)
        
        writer.add_scalar("Valid Accuracy", valid_accuracy/len(validloader), epoch)


        print('Epoch : {}/{}.....'.format(epoch+1, epochs),
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)),
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)),
              'Valid Accuracy : {:.3f}'.format(valid_accuracy/len(validloader)))
      

        if valid_accuracy > max_accuracy: 
          max_accuracy = valid_accuracy
          torch.save(model.state_dict(), 'best_checkpoint.pth')

        # Early Stopping
        if valid_loss > min_loss:
          trigger += 1 # valid lossê°€ min_loss ë¥¼ ê°±ì‹ í•˜ì§€ ëª»í• ë•Œë§ˆë‹¤ ì¦ê°€
          print('trigger : ', trigger )
          if trigger > patience:
            print('Early Stopping!!!')
            print('Traning step is finished!!')
            writer.flush()  
            return   
        else:
          trigger = 0
          min_loss = valid_loss


        train_loss = 0
        model.train()

        # Learning Rate Scheduler
        scheduler.step(valid_loss)
  plt.figure()
  plt.ylim(0,1.5)
  sns.lineplot(list(range(len(train_loss))), train_loss)
  sns.lineplot(list(range(len(valid_loss))), valid_loss)
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.legend(['Train','Val'])
  writer.flush()      
```


```python
epochs=20
train(model, epochs, criterion, optimizer)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:02<00:00,  1.15it/s]

    Epoch : 1/20..... Train Loss : 1.125 Valid Loss : 0.272 Valid Accuracy : 0.908
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:11<00:00,  1.63it/s]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [03:56<00:00,  2.39it/s]

    Epoch : 2/20..... Train Loss : 0.458 Valid Loss : 0.224 Valid Accuracy : 0.940
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:05<00:00,  1.67it/s]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:13<00:00,  1.62it/s]
    

    Epoch : 3/20..... Train Loss : 0.342 Valid Loss : 0.200 Valid Accuracy : 0.924
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:05<00:00,  1.67it/s]
    

    Epoch : 4/20..... Train Loss : 0.283 Valid Loss : 0.229 Valid Accuracy : 0.940
    trigger :  1
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:06<00:00,  1.74it/s]

    Epoch : 5/20..... Train Loss : 0.232 Valid Loss : 0.182 Valid Accuracy : 0.946
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:15<00:00,  1.61it/s]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:04<00:00,  1.68it/s]
    

    Epoch : 6/20..... Train Loss : 0.252 Valid Loss : 0.169 Valid Accuracy : 0.929
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:14<00:00,  1.61it/s]
    

    Epoch : 7/20..... Train Loss : 0.197 Valid Loss : 0.241 Valid Accuracy : 0.924
    trigger :  1
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:14<00:00,  1.61it/s]
    

    Epoch : 8/20..... Train Loss : 0.174 Valid Loss : 0.181 Valid Accuracy : 0.946
    trigger :  2
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:04<00:00,  1.89it/s]

    Epoch : 9/20..... Train Loss : 0.140 Valid Loss : 0.198 Valid Accuracy : 0.951
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:13<00:00,  1.62it/s]
    

    trigger :  3
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:07<00:00,  1.66it/s]
    

    Epoch : 10/20..... Train Loss : 0.147 Valid Loss : 0.181 Valid Accuracy : 0.946
    trigger :  4
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:15<00:00,  1.88it/s]

    Epoch : 11/20..... Train Loss : 0.134 Valid Loss : 0.122 Valid Accuracy : 0.962
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:24<00:00,  1.55it/s]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:03<00:00,  1.68it/s]
    

    Epoch : 12/20..... Train Loss : 0.153 Valid Loss : 0.163 Valid Accuracy : 0.951
    trigger :  1
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:15<00:00,  1.60it/s]
    

    Epoch : 13/20..... Train Loss : 0.132 Valid Loss : 0.193 Valid Accuracy : 0.951
    trigger :  2
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:17<00:00,  1.59it/s]
    

    Epoch : 14/20..... Train Loss : 0.124 Valid Loss : 0.163 Valid Accuracy : 0.962
    trigger :  3
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:15<00:00,  1.60it/s]
    

    Epoch : 15/20..... Train Loss : 0.120 Valid Loss : 0.148 Valid Accuracy : 0.957
    trigger :  4
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:05<00:00,  2.06it/s]

    Epoch : 16/20..... Train Loss : 0.080 Valid Loss : 0.187 Valid Accuracy : 0.973
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [04:14<00:00,  1.61it/s]
    

    trigger :  5
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 409/410 [04:21<00:00,  1.57it/s]

    Epoch : 17/20..... Train Loss : 0.108 Valid Loss : 0.241 Valid Accuracy : 0.946
    trigger :  6
    Early Stopping!!!
    Traning step is finished!!
    

    
    

# SaveModel


```python
model
```




    ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=2048, out_features=1000, bias=True)
    )




```python
model.state_dict().keys()
```




    odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])




```python
torch.save(model, f'./model.pt')
```

# TestSubmission


```python
dataset_test = ImageDataset(test, img_dir=img_dir, 
                            transform=transform_test, is_test=True)


# TTAìš© ë°ì´í„°ì…‹ ë° ë°ì´í„° ë¡œë”
dataset_TTA = ImageDataset(test, img_dir=img_dir, 
                           transform=transform_train, is_test=True)
loader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, 
                        shuffle=False, worker_init_fn=seed_worker,
                        generator=g, num_workers=2)
```


```python
model.eval() # ëª¨ë¸ì„ í‰ê°€ ìƒíƒœë¡œ ì„¤ì • 

preds_test = np.zeros((len(test), 4)) # ì˜ˆì¸¡ê°’ ì €ì¥ìš© ë°°ì—´ ì´ˆê¸°í™”

with torch.no_grad():
    for i, images in enumerate(testloader):
        images = images.to(device)
        outputs = model(images)
        # íƒ€ê¹ƒ ì˜ˆì¸¡ í™•ë¥ 
        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()
        preds_test[i*batch_size:(i+1)*batch_size] += preds_part
submission_test = submission.copy() # ì œì¶œ ìƒ˜í”Œ íŒŒì¼ ë³µì‚¬

submission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test
```


```python
submission_test.to_csv('submission_test.csv', index=False)
# submission_tta.to_csv('submission_tta.csv', index=False)
```


```python
# predict = []
# for batch_idx in tqdm(enumerate(testloader)):
#     data = d['image'].cuda()
    
#     output = model(data)
#     output = output.cpu().detach().numpy()
    #output = np.argmax(output)
#     predict.append(output)
    #print(output)
```

    0it [00:00, ?it/s]
    


    ---------------------------------------------------------------------------

    IndexError                                Traceback (most recent call last)

    /tmp/ipykernel_23/2365087927.py in <module>
          1 predict = []
          2 for batch_idx in tqdm(enumerate(testloader)):
    ----> 3     data = d['image'].cuda()
          4 
          5     output = model(data)
    

    IndexError: too many indices for tensor of dimension 4

